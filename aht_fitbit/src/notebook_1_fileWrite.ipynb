{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aht_fitbit import main \n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "vars = main.get_vars()\n",
    "\n",
    "vol = vars['vol']\n",
    "date_0 = vars['date_0']\n",
    "date_1 = vars['date_1']\n",
    "date_7 = vars['date_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date_0)\n",
    "print(date_1)\n",
    "print(date_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import re\n",
    "\n",
    "def getMaxDatefromDir(dir):\n",
    "  df = spark.createDataFrame(dbutils.fs.ls(dir))\n",
    "  _max = df.select(f.max(df.name)).collect()[0]['max(name)'] \n",
    "  pattern = r'[^0-9]'\n",
    "  # Match all digits in the string and replace them with an empty string\n",
    "  strMax = re.sub(pattern, '', _max)\n",
    "  date_obj = dt.datetime.strptime(strMax, '%Y%m%d').date()\n",
    "  return date_obj,_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_dir = f\"dbfs:{vol}/raw_fitbitapi/sleep\"\n",
    "act_dir = f\"dbfs:{vol}/raw_fitbitapi/activities\"\n",
    "actLogs_dir = f\"dbfs:{vol}/raw_fitbitapi/activitylog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_maxSleepDate,_maxSleepFile = getMaxDatefromDir(sleep_dir)\n",
    "_maxActDate,_maxActFile = getMaxDatefromDir(act_dir)\n",
    "_maxActLogsDate, _maxLogsFile = getMaxDatefromDir(actLogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_maxSleepDate)\n",
    "print(_maxActDate)\n",
    "print(_maxActLogsDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REST MAX Activity Log Date - This API comes to us in a different way, \n",
    "# feed is not 1:1 with data, one day file can contain up to 100 acitivity logs, \n",
    "# we will get the max available date and add a buffer of -1 days \n",
    "\n",
    "def getMaxActLogDate(file): \n",
    "  actLogDf = spark.read.json(f'{actLogs_dir}/{file}')\n",
    "  actLogDf= (actLogDf.select(\"activities\")\n",
    "            .select(\"*\", f.explode(actLogDf.activities).alias(\"activities_exploded\"))\n",
    "  )\n",
    "  actLogDT =  actLogDf.select(\"activities.startTime\").distinct().collect()[0][0][-1][0:10]\n",
    "  __maxActLogsDate =  (dt.datetime.strptime(actLogDT, '%Y-%m-%d').date()  - dt.timedelta(days = 1))\n",
    "  return __maxActLogsDate\n",
    "\n",
    "try: \n",
    "  __maxActLogsDate = getMaxActLogDate(_maxLogsFile)\n",
    "  print(\"original input worked\")\n",
    "except: \n",
    "  print(\"original input did not work\")\n",
    "  dbutils.fs.rm(f\"{actLogs_dir}/{_maxLogsFile}\")\n",
    "  _maxActLogsDate, _maxLogsFile = getMaxDatefromDir(actLogs_dir)\n",
    "  __maxActLogsDate = getMaxActLogDate(_maxLogsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"_maxSleepDate: \" f\"{_maxSleepDate}\")\n",
    "print(\"_maxActDate: \" f\"{_maxActDate}\")\n",
    "print(\"_maxActLogsDate: \" f\"{__maxActLogsDate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = main.get_creds()\n",
    "creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.s3_interval_update(creds,vars,'sleep',_maxSleepDate,date_0,10)\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~SLEEP COMPLETE~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "main.s3_interval_update(creds,vars,'activities',_maxActDate,date_1,10)\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~ACTIVITIES COMPLETE~~~~~~~~~~~~~~~~~~~~~')\n",
    "main.s3_interval_activities(creds,vars,__maxActLogsDate,date_0,10,10)\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~ACTIVITY LOGS AND TCX COMPLETE~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_restore(start,end):\n",
    "  \"\"\"\n",
    "  This function takes a 2 strings, a start and end date of format '2023-01-01' and performs a bulk reload of fitbit data\n",
    "  \"\"\"\n",
    "  start= dt.datetime.strptime(start, '%Y-%m-%d').date()\n",
    "  end = dt.datetime.strptime(end, '%Y-%m-%d').date()\n",
    "\n",
    "  creds = main.get_creds()\n",
    "\n",
    "  #####################################################\n",
    "  ##                   RESTORES                     ###\n",
    "  #####################################################\n",
    "  #s3_interval_update('sleep',start,end,20,access_token)\n",
    "  #s3_interval_update('activities',start,end,20,access_token)\n",
    "  main.s3_interval_activities(creds,start,end,10,20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
