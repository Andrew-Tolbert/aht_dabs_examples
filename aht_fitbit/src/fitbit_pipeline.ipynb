{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a626959-61c8-4bba-84d2-2a4ecab1f7ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# DLT pipeline\n",
    "\n",
    "This Delta Live Tables (DLT) definition is executed using a pipeline defined in resources/aht_fitbit_pipeline.yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9198e987-5606-403d-9f6d-8f14e6a4017f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import DLT and src/aht_fitbit\n",
    "import dlt\n",
    "import sys\n",
    "sys.path.append(spark.conf.get(\"bundle.sourcePath\", \".\"))\n",
    "from aht_fitbit import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fc19dba-61fd-4a89-8f8c-24fee63bfb14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import explode, struct, from_json,col,first,arrays_zip,col,map_from_entries,expr,to_timestamp,to_date,array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = main.get_vars()\n",
    "vol = vars['vol']+'/raw_fitbitapi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Parsing fitbit sleep data from JSON delivery - using volumes\"\n",
    ")\n",
    "def bronze_sleep():\n",
    "  return (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "    .load(f\"{vol}/sleep\")\n",
    "    .filter(col(\"sleep\") !=array())\n",
    "    .select('summary',explode('sleep').alias('sleep'))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Parsing bronze to silver, exploding structs \"\n",
    ")\n",
    "def silver_sleep():\n",
    "  return (\n",
    "    dlt.read('bronze_sleep')\n",
    "    .select(to_date(col('sleep.dateOfSleep'), 'yyyy-MM-dd').alias('dateOfSleep')\n",
    "            ,to_timestamp(col('sleep.startTime')).alias('startTime')\n",
    "            ,to_timestamp(col('sleep.endTime')).alias('endTime')\n",
    "            ,col('summary.totalMinutesAsleep').cast('int').alias('totalMinutesAsleep')\n",
    "            ,col('summary.totalSleepRecords').cast('int').alias('totalSleepRecords')\n",
    "            ,col('summary.totalTimeInBed').cast('int').alias('totalTimeInBed')\n",
    "            ,col('sleep.efficiency').cast('int').alias('efficiency')\n",
    "            ,col('sleep.isMainSleep').alias('isMainSleep')\n",
    "            ,'summary.stages'\n",
    "            )\n",
    "    .sort(\"dateOfSleep\", ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitbit Actitivy Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Raw Delivery of json data to Delta Lake\"\n",
    ")\n",
    "def raw_activities():\n",
    "  return (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "    .load(f\"{vol}/activitylog\")\n",
    "    )\n",
    "\n",
    "\n",
    "@dlt.table(\n",
    "  comment=\"Load and flatten activities into Bronze\" \n",
    ")\n",
    "def bronze_activities():\n",
    "  return (\n",
    "    dlt.read_stream(\"raw_activities\")\n",
    "        .select(explode(\"activities\").alias(\"activities_exploded\"))\n",
    "        .select('activities_exploded.*')\n",
    "        .drop('source')\n",
    "    )\n",
    "\n",
    "@dlt.table(\n",
    "  comment=\"Parse Data - load distincts and convert maps to structs in silver\" \n",
    ")\n",
    "def silver_activities():\n",
    "  return (\n",
    "    dlt.read(\"bronze_activities\")\n",
    "            .distinct()\n",
    "            .withColumn(\n",
    "                \"activityLevelMap\",\n",
    "                map_from_entries(\n",
    "                    expr(\"transform(activityLevel, x -> struct(x.name, x.minutes))\")\n",
    "                )\n",
    "            )\n",
    "            .withColumn(\n",
    "                \"heartRateZonesMap\",\n",
    "                map_from_entries(\n",
    "                    expr(\"transform(heartRateZones, x -> struct(x.name, struct(x.caloriesOut, x.max, x.min, x.minutes)))\")\n",
    "                )\n",
    "            )\n",
    "            .selectExpr(\n",
    "                    \"logId\", \n",
    "                    \"startTime\",\n",
    "                    \"activityName\",\n",
    "                    \"steps\",\n",
    "                    \"speed\",\n",
    "                    \"pace\",\n",
    "                    \"duration\",\n",
    "                    \"logType\",\n",
    "                    \"averageHeartRate\",\n",
    "                    \"calories\",\n",
    "                    \"distance\",\n",
    "                    \"distanceUnit\",\n",
    "                    \"hasActiveZoneMinutes\",\n",
    "                    \"hasGps\",\n",
    "                    \"activityLevelMap as activityLevels\", \n",
    "                    \"heartRateZonesMap as heartRateZones\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to Parse XML Data from Fitbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Parsing fitbit sleep data from XML - TCX Files\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_xml\", \"Activity.Lap IS NOT NULL\")\n",
    "def raw_tcx():\n",
    "  return (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "          .option(\"cloudFiles.format\", \"xml\")\n",
    "          .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "          .option(\"mergeSchema\", \"true\") \n",
    "          .option(\"rowTag\", \"Activities\")  # Replace with the appropriate row tag\n",
    "          .load(f'{vol}/TCX')\n",
    "          .selectExpr(\"*\", \"_metadata as source_metadata\")\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "dlt_pipeline",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
